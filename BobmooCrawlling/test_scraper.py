#!/usr/bin/env python3
"""
ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import logging
from web_scraper import WebScraper
from gemini_parser import GeminiParser

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

async def test_scraper():
    """ìŠ¤í¬ë˜í¼ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    
    # í…ŒìŠ¤íŠ¸ URL (ì‹¤ì œ ì‹ë‹¹ ë©”ë‰´ ì‚¬ì´íŠ¸ë¡œ ë³€ê²½í•˜ì„¸ìš”)
    test_url = "https://example.com"
    
    try:
        print("ğŸ§ª ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # ì›¹ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸
        scraper = WebScraper()
        print("ğŸ“¡ HTML ìŠ¤í¬ë˜í•‘ ì¤‘...")
        html_content = await scraper.scrape_html(test_url, wait_time=2000)
        print(f"âœ… HTML ìŠ¤í¬ë˜í•‘ ì™„ë£Œ (ê¸¸ì´: {len(html_content)} ë¬¸ì)")
        
        # HTML ì •ë¦¬ í…ŒìŠ¤íŠ¸
        print("ğŸ§¹ HTML ì •ë¦¬ ì¤‘...")
        clean_text = scraper.clean_html(html_content)
        print(f"âœ… HTML ì •ë¦¬ ì™„ë£Œ (ê¸¸ì´: {len(clean_text)} ë¬¸ì)")
        
        # Gemini íŒŒì„œ í…ŒìŠ¤íŠ¸ (API í‚¤ê°€ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ)
        try:
            parser = GeminiParser()
            print("ğŸ¤– Gemini API ë¶„ì„ ì¤‘...")
            json_data = parser.parse_html_to_json(clean_text[:1000])  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 1000ìë§Œ
            print("âœ… Gemini API ë¶„ì„ ì™„ë£Œ")
            print(f"ğŸ“Š ì¶”ì¶œëœ ë°ì´í„°: {json_data}")
        except Exception as e:
            print(f"âš ï¸ Gemini API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        
        print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    asyncio.run(test_scraper())
